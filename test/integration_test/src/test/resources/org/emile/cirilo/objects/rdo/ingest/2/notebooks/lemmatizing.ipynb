{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatizing files using spaCy\n",
    "\n",
    "In this notebook, we will lemmatize our corpus. This needs to be done for each language separately. Lemmatizing is not obligatory for Topic Modeling, but if your lemmatization model works well with your corpus, we recommend it, since this can improve the quality of the topics.<br>  \n",
    "<i>spaCy</i> is a python library for natural language processing. See more: https://spacy.io/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from cophi_toolbox import preprocessing\n",
    "import metadata_toolbox.utils as metadata\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'Y:/data/projekte/dispecs/topicModeling'\n",
    "language = 'de' # language 2 letter abbreviation\n",
    "path_to_corpus = Path(data, 'dispecs_'+language+'_lemmatized') # Careful! The files will be overwritten, so make a backup :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '{year}_{journal}_{author}_{volume}_{issue}_{id}'#1716_Le-Spectateur-ou-le-Socrate-moderne_Anonym_Table-des-Matieres_119-1257\n",
    "meta = pd.concat([metadata.fname2metadata(str(path), pattern=pattern) for path in path_to_corpus.glob('*.txt')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>journal</th>\n",
       "      <th>author</th>\n",
       "      <th>volume</th>\n",
       "      <th>issue</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_de_lemmatized\\1723_Der-Leipziger-Spectateur_Anonymus_Vol-1_Nr-000_4287.txt</th>\n",
       "      <td>1723</td>\n",
       "      <td>Der-Leipziger-Spectateur</td>\n",
       "      <td>Anonymus</td>\n",
       "      <td>Vol-1</td>\n",
       "      <td>Nr-000</td>\n",
       "      <td>4287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_de_lemmatized\\1723_Der-Leipziger-Spectateur_Anonymus_Vol-1_Nr-001_4281.txt</th>\n",
       "      <td>1723</td>\n",
       "      <td>Der-Leipziger-Spectateur</td>\n",
       "      <td>Anonymus</td>\n",
       "      <td>Vol-1</td>\n",
       "      <td>Nr-001</td>\n",
       "      <td>4281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_de_lemmatized\\1723_Der-Leipziger-Spectateur_Anonymus_Vol-1_Nr-002_4282.txt</th>\n",
       "      <td>1723</td>\n",
       "      <td>Der-Leipziger-Spectateur</td>\n",
       "      <td>Anonymus</td>\n",
       "      <td>Vol-1</td>\n",
       "      <td>Nr-002</td>\n",
       "      <td>4282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_de_lemmatized\\1723_Der-Leipziger-Spectateur_Anonymus_Vol-1_Nr-003_4283.txt</th>\n",
       "      <td>1723</td>\n",
       "      <td>Der-Leipziger-Spectateur</td>\n",
       "      <td>Anonymus</td>\n",
       "      <td>Vol-1</td>\n",
       "      <td>Nr-003</td>\n",
       "      <td>4283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_de_lemmatized\\1723_Der-Leipziger-Spectateur_Anonymus_Vol-1_Nr-004_4284.txt</th>\n",
       "      <td>1723</td>\n",
       "      <td>Der-Leipziger-Spectateur</td>\n",
       "      <td>Anonymus</td>\n",
       "      <td>Vol-1</td>\n",
       "      <td>Nr-004</td>\n",
       "      <td>4284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    year  \\\n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  1723   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  1723   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  1723   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  1723   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  1723   \n",
       "\n",
       "                                                                     journal  \\\n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  Der-Leipziger-Spectateur   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  Der-Leipziger-Spectateur   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  Der-Leipziger-Spectateur   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  Der-Leipziger-Spectateur   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  Der-Leipziger-Spectateur   \n",
       "\n",
       "                                                      author volume   issue  \\\n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  Anonymus  Vol-1  Nr-000   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  Anonymus  Vol-1  Nr-001   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  Anonymus  Vol-1  Nr-002   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  Anonymus  Vol-1  Nr-003   \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  Anonymus  Vol-1  Nr-004   \n",
       "\n",
       "                                                      id  \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  4287  \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  4281  \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  4282  \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  4283  \n",
       "Y:\\data\\projekte\\dispecs\\topicModeling\\dispecs_...  4284  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German package loaded\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-----> Language packages (have to be installed first, see here: https://spacy.io/usage/models):\n",
    "French: fr_core_news_lg\n",
    "Spanish: es_core_news_lg\n",
    "Italian: it_core_news_lg\n",
    "English: en_core_web_lg\n",
    "Portuguese: pt_core_news_lg\n",
    "German: de_core_news_lg\n",
    "\"\"\"\n",
    "if language == 'fr':\n",
    "    nlp = spacy.load('fr_core_news_lg')\n",
    "    print('French package loaded')\n",
    "if language == 'it':\n",
    "    nlp = spacy.load('it_core_news_lg')\n",
    "    print('Italian package loaded')\n",
    "if language == 'es':\n",
    "    nlp = spacy.load('es_core_news_lg')\n",
    "    print('Spanish package loaded')\n",
    "if language == 'de':\n",
    "    nlp = spacy.load('de_core_news_lg')\n",
    "    print('German package loaded')\n",
    "if language == 'en':\n",
    "    nlp = spacy.load('en_core_web_lg')\n",
    "    print('English package loaded')\n",
    "if language == 'pt':\n",
    "    nlp = spacy.load('pt_core_news_lg')\n",
    "    print('Portuguese package loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma dixo corrected with decir\n",
      "Lemma decia corrected with decir\n",
      "Lemma Dixo corrected with decir\n",
      "Lemma Decia corrected with decir\n",
      "Lemma iba corrected with ir\n",
      "Lemma Iba corrected with ir\n",
      "Lemma parecia corrected with pacerer\n",
      "Lemma Parecia corrected with pacerer\n",
      "Lemma podia corrected with poder\n",
      "Lemma Podia corrected with poder\n",
      "Lemma fuesse corrected with ser\n",
      "Lemma Fuesse corrected with ser\n",
      "Lemma habia corrected with haber\n",
      "Lemma havia corrected with haber\n",
      "Lemma Habia corrected with haber\n",
      "Lemma Havia corrected with haber\n",
      "Lemma aora corrected with ahora\n",
      "Lemma Aora corrected with ahora\n",
      "Lemma estàn corrected with estar\n",
      "Lemma Estàn corrected with estar\n",
      "Lemma luxo corrected with lujo\n",
      "Lemma luxar corrected with lujo\n",
      "Lemma Luxo corrected with lujo\n",
      "Lemma Luxar corrected with lujo\n",
      "Lemma razon corrected with razón\n",
      "Lemma razòn corrected with razón\n",
      "Lemma Razon corrected with razón\n",
      "Lemma Razòn corrected with razón\n",
      "Lemma cavallero corrected with caballero\n",
      "Lemma Cavallero corrected with caballero\n",
      "Lemma muger corrected with mujer\n",
      "Lemma mugeres corrected with mujer\n",
      "Lemma Muger corrected with mujer\n",
      "Lemma Mugeres corrected with mujer\n",
      "Lemma vèz corrected with vez\n",
      "Lemma Vèz corrected with vez\n",
      "Lemma jamas corrected with jamás\n",
      "Lemma Jamas corrected with jamás\n",
      "Lemma demas corrected with demás\n",
      "Lemma demàs corrected with demás\n",
      "Lemma Demas corrected with demás\n",
      "Lemma Demàs corrected with demás\n",
      "Lemma cuydado corrected with cuidar\n",
      "Lemma Cuydado corrected with cuidar\n",
      "Lemma possible corrected with posible\n",
      "Lemma Possible corrected with posible\n",
      "Lemma comediar corrected with comedia\n",
      "Lemma Comedias corrected with comedia\n",
      "Lemma poetas corrected with poeta\n",
      "Lemma Poetas corrected with poeta\n",
      "Lemma manir corrected with mano\n",
      "Lemma Manir corrected with mano\n",
      "Lemma barbar corrected with barba\n",
      "Lemma Barbar corrected with barba\n",
      "Lemma ideo corrected with idea\n",
      "Lemma Ideo corrected with idea\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Run this part only if there are corrections to be made! \n",
    "Make sure to set the right dictionary name in the variable \"correction_dictionary\"!\n",
    "Correct the lemmatization errors by defining your dictionaries and replacing the wrong lemma in the lookup table.\n",
    "The usage of upper and lowercase letters in values is relevant, so be sure to correct both versions, if needed.\n",
    "\"\"\"\n",
    "\n",
    "corr_fr = {\n",
    "    \"avoir\" : [\"avois\", \"avoit\", \"Avois\", \"Avoit\"], \n",
    "    \"dire\" : [\"disois\", \"disoit\", \"Disois\", \"Disoit\"],\n",
    "    \"manière\" : [\"maniere\", \"Maniere\"],\n",
    "    \"pièce\" : [\"piéce\", \"Piéce\"],\n",
    "    \"poète\" : [\"poëte\", \"Poëte\"],\n",
    "    \"poème\" : [\"poëme\", \"Poëme\"],\n",
    "    \"poésie\" : [\"poësie\", \"Poësie\"],\n",
    "    \"sexe\" : [\"séxe\", \"Séxe\"],\n",
    "    \"moyen\" : [\"moïen\", \"Moïen\"],\n",
    "    \"thèatre\":[\"théâtre\", \"Théâtre\"]\n",
    "        \n",
    "}\n",
    "\n",
    "corr_es = {\n",
    "    \"decir\":[\"dixo\", \"decia\", \"Dixo\", \"Decia\"],\n",
    "    \"ir\":[\"iba\", \"Iba\"],\n",
    "    \"pacerer\":[\"parecia\", \"Parecia\"],\n",
    "    \"poder\":[\"podia\", \"Podia\"],\n",
    "    \"ser\":[\"fuesse\", \"Fuesse\"],\n",
    "    \"haber\":[\"habia\", \"havia\", \"Habia\", \"Havia\"],\n",
    "    \"ahora\" : [\"aora\", \"Aora\"],\n",
    "    \"estar\" : [\"estàn\", \"Estàn\"],\n",
    "    \"lujo\" : [\"luxo\",\"luxar\", \"Luxo\",\"Luxar\"],\n",
    "    \"razón\" : [\"razon\", \"razòn\", \"Razon\", \"Razòn\"],\n",
    "    \"caballero\" : [\"cavallero\", \"Cavallero\"],\n",
    "    \"mujer\" : [\"muger\", \"mugeres\", \"Muger\", \"Mugeres\"],\n",
    "    \"vez\" : [\"vèz\", \"Vèz\"],\n",
    "    \"jamás\" : [\"jamas\", \"Jamas\"],\n",
    "    \"demás\" : [\"demas\", \"demàs\", \"Demas\", \"Demàs\"],\n",
    "    \"cuidar\" : [\"cuydado\", \"Cuydado\"],\n",
    "    \"posible\" : [\"possible\", \"Possible\"],\n",
    "    \"comedia\":[\"comediar\", \"Comedias\"],\n",
    "    \"poeta\":[\"poetas\", \"Poetas\"],\n",
    "    \"mano\":[\"manir\", \"Manir\"],\n",
    "    \"barba\":[\"barbar\", \"Barbar\"],\n",
    "    \"idea\":[\"ideo\", \"Ideo\"]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Choose the dictionary by setting the right value in the variable \"correction_dictionary\"\n",
    "correction_dictionary = corr_es\n",
    "for key, value in correction_dictionary.items():\n",
    "    for token in value:\n",
    "        correct = key\n",
    "        wrong = token\n",
    "        nlp.vocab.lookups.get_table(\"lemma_lookup\")[token] = key\n",
    "        print(\"Lemma\", token, \"corrected with\", key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization of all text files in the corpus. The files will be overwritten. \n",
    "\n",
    "for file in path_to_corpus.glob('*.txt'): \n",
    "    with open(file, encoding='utf-8') as f:\n",
    "        original = f.read()\n",
    "        lemmatized_object = nlp(original)        \n",
    "        lemma_list = []\n",
    "        for lemma in lemmatized_object:\n",
    "            lemma_list.append(lemma.lemma_)\n",
    "        lemma_doc = ' '.join(lemma_list)\n",
    "    with open(file, 'w', encoding='utf-8') as f:\n",
    "        f.write(lemma_doc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
